{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport scipy.io\nimport time","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets read our CFD results of lift-drag ratio data containing for different airfoils\n\ndata = scipy.io.loadmat('../input/data-mat/1_300.mat')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating X, y values from the dictionary\nX, y, rNorm = data['data_x'], data['data_y'], data['Normalization_Factor']","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the sape of the X value\nX.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(6855, 16384)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"so we have 6855 examples and flattened 128-by-128 image vector <br>\nwe can look one of the image from our dataset below"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X.reshape(-1,128,128)[17])\nplt.show()","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the shape of the X value\ny.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(6855, 1)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"we have one lift-drag ratio value for each example"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, test_size=0.9, random_state=47)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Shape of Train data: {X_train.shape} \\n')\nprint(f'Shape of Validation data: {X_val.shape} \\n')\nprint(f'Shape of Test data: {X_test.shape}')","execution_count":10,"outputs":[{"output_type":"stream","text":"Shape of Train data: (5244, 16384) \n\nShape of Validation data: (582, 16384) \n\nShape of Test data: (1029, 16384)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(-1,128,128,1)\nX_val = X_val.reshape(-1,128,128,1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets define our image shape\nIMAGE_WIDTH = 128\nIMAGE_HEIGHT = 128\nIMAGE_CHANNELS = 1","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set up parameters\nbatch_size = 32\nlearning_rate = 1e-5\nnum_epochs = 50","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import backend as k\n\nfrom tensorflow.keras.models import Model, Sequential\n\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D\nfrom tensorflow.keras.layers import Flatten, Dense, Activation, BatchNormalization, Concatenate","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = Sequential()\n\n#model.add(Input(shape=(IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)))\n#model.add(Conv2D(5, (3, 3), padding='same', activation='relu'))\n#model.add(BatchNormalization(axis=3))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n#model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n#model.add(BatchNormalization(axis=3))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n#model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n#model.add(BatchNormalization(axis=3))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n#model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n#model.add(BatchNormalization(axis=3))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n\n#model.add(Flatten())\n#model.add(Dense(256, activation='relu'))\n#model.add(Flatten())\n#model.add(Dense(64, activation='relu'))\n#model.add(Dense(1, activation='sigmoid'))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS))\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1) \npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\ndrop4 = Dropout(0.5)(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\ndrop5 = Dropout(0.5)(conv5)\n\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\nmerge6 = Concatenate(axis = 3)([drop4,up6])\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\nmerge7 = Concatenate(axis = 3)([conv3,up7])\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\nmerge8 = Concatenate(axis = 3)([conv2,up8])\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\nmerge9 = Concatenate(axis = 3)([conv1,up9])\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\nconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n\nflat = Flatten()(conv9)\n\nconv10 = Dense(1, activation = 'sigmoid')(flat)\n\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs = inputs , outputs = conv10)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":18,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 128, 128, 64) 640         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 128, 128, 64) 36928       conv2d[0][0]                     \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_6[0][0]                   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)    0           dropout[0][0]                    \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 8, 8, 1024)   4719616     max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 8, 8, 1024)   9438208     conv2d_8[0][0]                   \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 8, 8, 1024)   0           conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 16, 16, 1024) 0           dropout_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 16, 16, 512)  2097664     up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 16, 16, 1024) 0           dropout[0][0]                    \n                                                                 conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 16, 16, 512)  4719104     concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 32, 32, 256)  524544      up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_5[0][0]                   \n                                                                 conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_3[0][0]                   \n                                                                 conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_1[0][0]                   \n                                                                 conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 128, 128, 2)  1154        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 32768)        0           conv2d_22[0][0]                  \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1)            32769       flatten[0][0]                    \n==================================================================================================\nTotal params: 31,064,451\nTrainable params: 31,064,451\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),  #SGD(lr=0.005, momentum=0.9), #Adam(learning_rate = 2e-4),\n                        loss = tf.keras.losses.MSE, #'categorical_crossentropy'\n                        metrics = ['mse']) #'acc'","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stop training when the val_loss has stopped decreasing for 5 epochs.\nes = EarlyStopping(monitor='val_loss', mode='min', patience=5,\n                       restore_best_weights=True, verbose=1)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN = len(X_train)//batch_size\nSTEP_SIZE_VALID = len(X_val)//batch_size","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce learning rate\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                                  factor = 0.3,\n                                  patience = 3,\n                                  min_lr = 1e-8,\n                                  mode = 'min',\n                                  verbose = 1)\n\n# Save the model with the minimum validation loss\ncheckpoint_cb = ModelCheckpoint(\"./best_model.h5\",\n                                    save_best_only=True,\n                                    monitor = 'val_loss',\n                                    mode='min')\n    \nhistory = model.fit(x=X_train,y=y_train, validation_data=(X_val,y_val), \n                    steps_per_epoch = STEP_SIZE_TRAIN,\n                    validation_steps = STEP_SIZE_VALID,\n                    callbacks=[es, reduce_lr],\n                    batch_size= batch_size,epochs= num_epochs)","execution_count":23,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n163/163 [==============================] - 50s 269ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0178 - val_mse: 0.0178\nEpoch 2/50\n163/163 [==============================] - 45s 265ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0082 - val_mse: 0.0082\nEpoch 3/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0059 - val_mse: 0.0059\nEpoch 4/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0052 - val_mse: 0.0052\nEpoch 5/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0050 - val_mse: 0.0050\nEpoch 6/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\nEpoch 7/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0040 - val_mse: 0.0040\nEpoch 8/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0037 - val_mse: 0.0037\nEpoch 9/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0036 - val_mse: 0.0036\nEpoch 10/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0036 - val_mse: 0.0036\nEpoch 11/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0033 - val_mse: 0.0033\nEpoch 12/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0033 - val_mse: 0.0033\nEpoch 13/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0031 - val_mse: 0.0031\nEpoch 14/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0029 - val_mse: 0.0029\nEpoch 15/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0031 - val_mse: 0.0031\nEpoch 16/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0027 - val_mse: 0.0027\nEpoch 17/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0026 - val_mse: 0.0026\nEpoch 18/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0030 - val_mse: 0.0030\nEpoch 19/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0028 - val_mse: 0.0028\nEpoch 20/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0022 - val_mse: 0.0022\nEpoch 21/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0026 - val_mse: 0.0026\nEpoch 22/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0022 - val_mse: 0.0022\nEpoch 23/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0025 - val_mse: 0.0025\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 2.9999999242136253e-06.\nEpoch 24/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0021 - val_mse: 0.0021\nEpoch 25/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\nEpoch 26/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 27/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 8.999999636216671e-07.\nEpoch 28/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\nEpoch 29/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 30/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 31/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\nEpoch 32/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 33/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 2.6999999249710525e-07.\nEpoch 34/50\n163/163 [==============================] - 43s 264ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 35/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 36/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\n\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-08.\nEpoch 37/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 38/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 39/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n\nEpoch 00039: ReduceLROnPlateau reducing learning rate to 2.4299998813148703e-08.\nEpoch 40/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 41/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\nEpoch 42/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n\nEpoch 00042: ReduceLROnPlateau reducing learning rate to 1e-08.\nEpoch 43/50\n163/163 [==============================] - 43s 265ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\nRestoring model weights from the end of the best epoch.\nEpoch 00043: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test.reshape(-1,128,128,1))\ny_pred.shape","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"(1029, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"(1029, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"array([[0.13586567],\n       [0.18700768],\n       [0.03278466],\n       ...,\n       [0.09403549],\n       [0.13799205],\n       [0.20296617]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([[0.09888653],\n       [0.18745521],\n       [0.00974133],\n       ...,\n       [0.09375846],\n       [0.07944649],\n       [0.240902  ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, r2_score","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test,y_pred)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"0.8167562859458307"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(loss))\n\nplt.figure(figsize=(25, 10))\n\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":30,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (1,) and (43,)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-3326de16acf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     return gca().plot(\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (43,)"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(loss)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"43"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#denormalize\npredyList = [x*rNorm[0,0] for x in y_pred]\ntestyList = [x*rNorm[0,0] for x in y_test]\n#plot result\nplt.figure(figsize=(20, 10))\nline3, = plt.plot(range(len(predyList)), predyList, alpha = 0.8,label = 'Predicted')\nline4, = plt.plot(range(len(testyList)), testyList, label = 'GroundTruth')\nplt.ylim(-100,150)\nplt.legend([line3,line4],['Predicted','GroundTruth'])\nplt.title(' Test & Predicted Cl/Cd Ratio')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot result(zoom in)\nplt.figure(figsize=(20,10))\nline5, = plt.plot(range(len(predyList)), predyList, alpha = 0.8,label = 'Predicted')\nline6, = plt.plot(range(len(testyList)), testyList, label = 'GroundTruth')\nplt.ylim(-100,150)\nplt.xlim(400,500)\nplt.legend([line5,line6],['Predicted','GroundTruth'])\nplt.title(' Test & Predicted Cl/Cd Ratio (Zoom In)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\npre = [x for x in predyList]\ntest = [x for x in testyList]\n#plt.figure()\nplt.scatter(pre, test,s=1)\n#plt.scatter(y_pred, y_test,s=1)\nplt.plot([-150,150],[-150,150], ls=\"--\",c=\".3\")\nplt.plot([-150,135],[-135,150], ls=\"--\",c=\".3\")\nplt.plot([-135,150],[-150,135], ls=\"--\",c=\".3\")\nplt.xlabel('Predicted Cl/Cd Ratio')\nplt.ylabel('Actual Cl/Cd Ratio')\nplt.xlim(-50,150)\nplt.ylim(-50,150)\nplt.title(' Test & Predicted confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}